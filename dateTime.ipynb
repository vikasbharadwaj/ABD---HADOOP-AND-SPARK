{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Test1').getOrCreate()\n",
    "\n",
    "from pyspark.sql.functions import current_date, current_timestamp, date_sub, date_add, col, datediff, to_date,to_timestamp, lit, date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----------------------+\n",
      "|id |today     |now                    |\n",
      "+---+----------+-----------------------+\n",
      "|0  |2021-01-11|2021-01-11 15:09:23.586|\n",
      "|1  |2021-01-11|2021-01-11 15:09:23.586|\n",
      "|2  |2021-01-11|2021-01-11 15:09:23.586|\n",
      "|3  |2021-01-11|2021-01-11 15:09:23.586|\n",
      "|4  |2021-01-11|2021-01-11 15:09:23.586|\n",
      "+---+----------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "dateDF = spark.range(10)\\\n",
    "    .withColumn('today', current_date())\\\n",
    "    .withColumn('now', current_timestamp())\n",
    "dateDF.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|date_sub(today, 15)|date_add(today, 5)|\n",
      "+-------------------+------------------+\n",
      "|         2020-12-27|        2021-01-16|\n",
      "|         2020-12-27|        2021-01-16|\n",
      "|         2020-12-27|        2021-01-16|\n",
      "|         2020-12-27|        2021-01-16|\n",
      "|         2020-12-27|        2021-01-16|\n",
      "|         2020-12-27|        2021-01-16|\n",
      "|         2020-12-27|        2021-01-16|\n",
      "|         2020-12-27|        2021-01-16|\n",
      "|         2020-12-27|        2021-01-16|\n",
      "|         2020-12-27|        2021-01-16|\n",
      "+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Example 2\n",
    "dateDF.select(date_sub('today',15),\n",
    "             date_add('today',5)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|datediff(Week_ago, today)|\n",
      "+-------------------------+\n",
      "|                       -7|\n",
      "|                       -7|\n",
      "|                       -7|\n",
      "|                       -7|\n",
      "|                       -7|\n",
      "|                       -7|\n",
      "|                       -7|\n",
      "|                       -7|\n",
      "|                       -7|\n",
      "|                       -7|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 3\n",
    "dateDF.withColumn('Week_ago', date_sub(col('today'), 7))\\\n",
    "    .select(datediff( col('Week_ago'), col('today'))).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      date|\n",
      "+----------+\n",
      "|2017-20-01|\n",
      "|2017-20-01|\n",
      "|2017-20-01|\n",
      "|2017-20-01|\n",
      "|2017-20-01|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 4\n",
    "spark.range(5).withColumn('date', lit('2017-20-01'))\\\n",
    "    .select('date').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|to_date(`date`)|\n",
      "+---------------+\n",
      "|           null|\n",
      "|           null|\n",
      "|           null|\n",
      "|           null|\n",
      "|           null|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 5\n",
    "spark.range(5).withColumn('date', lit('2017-20-01'))\\\n",
    "    .select(to_date(col('date'))).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|to_date(`date`, 'dd-MM-yyyy')|\n",
      "+-----------------------------+\n",
      "|                   2021-12-15|\n",
      "|                   2021-12-15|\n",
      "|                   2021-12-15|\n",
      "|                   2021-12-15|\n",
      "|                   2021-12-15|\n",
      "+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.range(5).withColumn('date', lit('15-12-2021'))\\\n",
    "    .select(to_date(col('date'),'dd-MM-yyyy')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|     date1|     date2|\n",
      "+----------+----------+\n",
      "|2020-03-05|2020-12-20|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 7\n",
    "myDate_format ='yyyy-dd-MM'\n",
    "cleanDateDf = spark.range(1).select(\n",
    "    to_date(lit('2020-05-03'), myDate_format).alias('date1'), \n",
    "    to_date(lit('2020-20-12'), myDate_format).alias('date2'))\n",
    "cleanDateDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+\n",
      "|      date|increment|  inc_date|\n",
      "+----------+---------+----------+\n",
      "|2019-01-23|        1|2019-02-23|\n",
      "|2019-06-24|        2|2019-08-24|\n",
      "|2019-09-20|        4|2020-01-20|\n",
      "+----------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import  expr\n",
    "data=[(\"2019-01-23\",1),(\"2019-06-24\",2),(\"2019-09-20\",4)]\n",
    "\n",
    "spark.createDataFrame(data).toDF(\"date\",\"increment\") \\\n",
    "    .select(col(\"date\"),col(\"increment\"), \\\n",
    "      expr(\"add_months(to_date(date,'yyyy-MM-dd'),cast(increment as int))\").alias(\"inc_date\")) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|      Date|New Format|\n",
      "+----------+----------+\n",
      "|2019-01-23|23-01-2019|\n",
      "|2019-06-24|24-06-2019|\n",
      "|2019-09-20|20-09-2019|\n",
      "+----------+----------+\n",
      "\n",
      "+----------+\n",
      "|  Modified|\n",
      "+----------+\n",
      "|23-01-2019|\n",
      "|24-06-2019|\n",
      "|20-09-2019|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display Date in required format\n",
    "data=[(\"2019-01-23\",1),(\"2019-06-24\",2),(\"2019-09-20\",4)]\n",
    "df = spark.createDataFrame(data).toDF(\"Date\",\"increment\")\n",
    "\n",
    "df.select('Date').withColumn('New Format',date_format(to_date('Date'),'dd-MM-yyyy')).show()\n",
    "\n",
    "df.select(date_format(to_date('Date'), 'dd-MM-yyyy').alias('Modified') ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
